{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_CNNs.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb","timestamp":1613851332047}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MhoQ0WE77laV"},"source":["#**Notes on CNNs**\n","\n","_(to be updated with code later)_"]},{"cell_type":"markdown","metadata":{"id":"FbVhjPpzn6BM"},"source":["This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."]},{"cell_type":"code","metadata":{"id":"dzLKpmZICaWN"},"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","\n","# Helper libraries\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","# print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JmgCKzIKEile"},"source":["___\n","**Convolutional networks** are neural networks that use convolution in place of general matrix multiplication in at least one layer. This operation is usually followed by another, called **pooling**."]},{"cell_type":"markdown","metadata":{"id":"5wD3Iw_GF0OM"},"source":["Here is the example they use to introduce convolution: we are tracking the position of a spaceship with a sensor. The output of the sensor is denoted $x(t)$, which we interpret as giving the position at time $t$. \n","\n","Suppose that the sensor is noisy -- one way to get a better estimate of the position of the ship is to average together several recent measurements. \n","\n","Let $w$ denote a probability density function, and let $a$ be a variable used to denote the age of a measurement. Averaging the measurements $x$ against $w$ gives us a smoother measurement denoted $s \\equiv s(t)$, defined by\n","\n","$$\n","s(t) := \\int x(a) w(t-a) da \n","$$\n","\n","This is to say, $s(t) = (x * w)(t)$. They mention that the support of $w$ should be on the non-negative real axis -- they say this is to avoid looking into the future: looking at the integral, this is equivalent to the enforced constraint $a \\leq t$.\n"]},{"cell_type":"markdown","metadata":{"id":"LpvalLXMJCxj"},"source":["___\n","In the above example, $x$ is usually referred to as the **input** and $w$ is called the **kernel**. They remark that, in their example, it might be more realistic to assume that their laser provides measurement at a sequence of time intervals with fixed spacing, in which case, the kernel $w$ is interpreted as a probability (mass) function, i.e. $\\sum_{k \\in \\mathbb{Z}} w(k) = 1$. \n","\n","Thus, if we assume $x$ and $w$ are only defined at integer values of $t$, the discrete convolution is defined as\n","$$\n","s(t) = (x * w) (t) := \\sum_{ a \\in \\mathbb{Z} } x(a) w(t-a) \n","$$"]},{"cell_type":"markdown","metadata":{"id":"UViVyaa7KfJD"},"source":["\n","___\n","In ML applications, the input is usually a multidimensional array of data, which we refer to as a **tensor**. If any of this is going into a computer, we need to work with a kernel that has finite support. Importantly, if our input is a tensor, the convolution operation is multi-dimensional. \n","\n","For example, if the input is an image, stored as a matrix, the \"features\" of the image are extracted by examining the image locally (in a CNN). "]},{"cell_type":"markdown","metadata":{"id":"Lhn8Gu-7OSAM"},"source":["\n","___\n","Convolution is commutative, and the following equivalent expression is easier / \"more straightforward\" to implement, \"because there is less variation in the range of valid values of $m$ and $n$:\"\n","$$\n","S(i,j) = (K *I ) (i,j) = \\sum_{m,\\,n} I(i-m,j-n) K(m,n)\n","$$\n","And, this feels a lot more like a \"weighted average\" of the image \n"]},{"cell_type":"markdown","metadata":{"id":"X2NxV6T1M68T"},"source":["___\n","If $(i,j)$ are coordinates of pixels of an image, (say it is grayscale, so the image is determined completely by a value assignment to each pixel. Let $I$ denote this image function. We convolve this with a two-dimensional kernel $K$:\n","$$\n","S(i,j) = (I * K) (i,j) = \\sum_{m,\\,n} I(m,n) K(i - m, j - n) \n","$$\n","People in ML have run with this expression: there is no need there to preserve the commutativitity of the convolution, they introduce the **cross-correlation**, which is defined as follows\n","$$\n","S(i,j) = (I *K) (i,j) = \\sum_{m,\\,n} I( i +m, j +n ) K(m,n) \n","$$"]},{"cell_type":"markdown","metadata":{"id":"ThcW_aAoRJwA"},"source":["\n","Discrete convolution (with kernel and input finite dimensional) can be viewed as multiplication by a matrix .\n","\n","Importantly, this matrix is constrained so that several entries are equal to other entries. For example, the matrix associated to single-variable convolution is such that each row is equal to the one above (a kind of Toeplitz matrix called a circulant matrix.)\n","\n","Suppose we want to consider the convolution of two discrete (one dimensional) signals \n","$$\n","x = \n","[\n","\\begin{matrix}\n","x_0 & x_1 & x_2 & x_3 \n","\\end{matrix}\n","]\n","$$\n","and\n","$$\n","w =\n","[\n","\\begin{matrix}\n","w_0 & w_1 & w_2 & w_3 \n","\\end{matrix}\n","]\n","$$\n","Where $x$ is a 4-dimensional input vector, and where $w$ is a 4-dimensional weight vector. We can view each as a function on a four-point space. \n","\n","To express the convolution of these functions in terms of matrix multiplication, we define the circulant matrix $W$ associated to the vector $w$ \n","$$\n","W\n","  :=\n","  \\left[\n","      \\begin{matrix}\n","        w_0 & w_1 & w_2 & w_3 \\\\\n","        w_3 & w_0 & w_1 & w_2\n","         \\\\\n","        w_2 & w_3 & w_0 & w_1 \\\\\n","        w_1 & w_2 & w_3 & w_0\n","      \\end{matrix}\n","  \\right]\n","$$\n","With this definition, we have that\n","$$\n","(x*w) = W x \n","$$\n","To see this, just write out the matrix multiplication. Let us use $a$ and $t$ because it is suggestive of the time-series input in the $1$-dimensional case:\n","$$\n","[Wx]_t = \n","  \\sum_{a = 0,1,2,3} \n","    W_{t,a} x_a   \n","$$ \n","which is\n","$$\n","[Wx]_t = \\sum_{a = 0}^3 w_{(t + a) \\text{mod} 4 } x_a \n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"jy5fZ_vCeyZl"},"source":["\n","___\n","Now we examine what convolution looks like for two-dimensional input data. This is more complicated, and requires a bit of setup: \n","\n","Let $x$ be a $2d$ input, represented as an $n \\times n$ matrix. Let $K$ denote a $m \\times m$ kernel. Concretely, suppose that $x$ is $3 \\times 3$, and write the entries as\n","$$\n","x = \n","\\left(\n","\\begin{matrix}\n","x_1 & x_2 & x_3 \\\\\n","x_4 & x_5 & x_6 \\\\\n","x_7 & x_8 & x_9 \n","\\end{matrix}\n","\\right)\n","$$\n","and \n","$$\n","K\n","=\n","\\left(\n","\\begin{matrix}\n","K_1 & K_2 \\\\\n","K_3 & K_4 \n","\\end{matrix}\n","\\right)\n","$$\n","The way to encode convolution of these two objects as matrix multiplication: embed both $K$ and $x$ into higher dimensional spaces via\n","$$\n","\\left(\n","  \\begin{matrix}\n","  K_1 & K_2 & 0 & K_3 & K_4 & 0 & 0 & 0 & 0 \\\\\n","  0 & K_1 & K_2 & 0 & K_3 & K_4 & 0 & 0 & 0 \\\\\n","  0 & 0 & 0 & K_1 & K_2 & 0 & K_3 & K_4 & 0 \\\\\n","  0 & 0 & 0 & 0 & K_1 & K_2 & 0 & K_3 & K_4 \n","  \\end{matrix}\n","\\right)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"yAmvU8ShsEmu"},"source":["\n","___\n","We can apply this matrix to $x$ after it's been reshaped into a length 9 vector. Thus, the effect of multiplying these two \"augmented\" objects is to form a vector of length four, with each entry of this vector corresponding to multiplication of the $2 \\times 2$ kernel acting on each $2 \\times 2$ block of $x$. \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EQEwb2eYUoqC"},"source":["\n","___\n","In addition to the periodicity in the matrix entries described above, there is also sparsity. The periodicity is synonymous with parameter sharing. These are two of the three (sparsity + parameter sharing) main motivations for CNNs. \n","\n","The third motivation is **equivariant representations**. A function $f$ is **equivariant** to a function $g$ if $f(g(x)) = g(f(x)$. In the case of a convolution \"matrix\" applied to the augmented input, this function is equivariant with respect to translations. In some sense, the convolution performs a coarse-graining on the image with block size determined by the kernel, and with block spacing another parameter to pay attention to. \n","\n","Equivariance is not invariance: all it means is that if we translate an image modulo its boundary, and then apply the convolution matrix, we get what we would have if we had first colvolved and then translated.\n"]},{"cell_type":"markdown","metadata":{"id":"BQJj0FSa4LxQ"},"source":["\n","Convolution is not naturally equivariant to other transformations, such as changes in scale or rotations of an image. "]},{"cell_type":"markdown","metadata":{"id":"bCO87HyS4vNa"},"source":["A convolution layer in a network typically consists of three stages: \n","\n","* applying convolution matrix to input to get pre-activation\n","* applying activation function to this to get the activation. This is sometimes called the detector stage.\n","* applying a pooling function to modify the output of the layer further\n","\n","A **pooling function** replaces the output of the net with a summary statistic of nearby outputs. \n","\n","It seems that the pooling layer gives us another chance to coarse-grain the data. One operation described is \"max-pooling\", which reports the maximum value in a block region. \n","\n","___\n","\"In all cases, pooling helps to make the representaiton become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change...\n","\n","...Invariance to local translation can be a very useful property if we care more about *whether* some feature is present than exactly where it is. \n","___\n","To understand better: \"pooling over spatial regions produces invariance to translation, but if we pool over the outputs of separately parametrized convolutions, the features can learn which transformations to become invariant to\"\n","... moreover,\n","\"pooling is essential for handling inputs of varying size\": we can equip any image with a grid that matches its aspect ratio, so that each picture contributes the same number of summary statistics. "]},{"cell_type":"markdown","metadata":{"id":"ohZsyxVG_SZy"},"source":["___\n","# Implementation"]},{"cell_type":"markdown","metadata":{"id":"iddwgQVw_YLg"},"source":["___\n","\n","## Keras API: Convolution layer types\n","\n","### `Conv1D` \n","\n","A one-dimensional convolution. _\"This layer creates a convolution kernel that is convolved with the layer input over a single spatial or temporal dimension to produce a tensor of outputs.\"_ \n","\n","### `Conv2D` \n","\n","Two-dimensional convolution\n","\n","### `Conv3D` \n","\n","A spatial convolution over volumes.\n","\n","### `SeparableConv1D`\n","\n","_\"Depthwise separable 1D convolution. This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels.\"_\n","\n","### `SeparableConv2D` \n","\n","_\"Depthwise separable 2D convolution. Separable convolutions consist of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes the resulting output channels. The `depth_multiplier` argument controls how many output channels are generated per input channel in the depthwise step.\"_\n","\n","_\"Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block\"_\n","\n","___\n","\n","**_Q_** : What is an inception block?\n","___\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JbgiQn_vCUDZ"},"source":["### `DepthwiseConv2D`\n","\n","_\"Depthwise separable 2D convolution. Consists of performing just the first step in a depthwise spatial convolution (which acts on each input channel separately).\"_\n","\n","### `Conv2DTranspose`\n","\n","_\"Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said transpose.\"_\n","\n","### `Conv3DTranspose`"]}]}